{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "IPLn_7GkhnOj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vFC4jGAhjm_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf \"/content/SBIC.v2.tgz\" -C \"/content/\""
      ],
      "metadata": {
        "id": "42I2Z10Qh0SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/SBIC.v2.trn.csv')"
      ],
      "metadata": {
        "id": "ga6KeWtgh34Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "NgORxqm7iCQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df['intentYN'].value_counts(dropna=False)\n",
        "plt.figure(figsize=(8, 5))\n",
        "category_counts.plot(kind='bar', color='skyblue')\n",
        "\n",
        "plt.title('Intent to Offend Counts', fontsize=18)\n",
        "plt.xlabel('Intent', fontsize=18)\n",
        "plt.ylabel('Count', fontsize=18)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "\n",
        "plt.savefig('/content/target_category.png', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n7-wFlqRiEpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "sYugwE2giPmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# replace nan values in order to use agglomerative clustering\n",
        "df['whoTarget'] = df['whoTarget'].fillna(-1)\n",
        "df['sexReason'] = df['sexReason'].fillna('')\n",
        "df['offensiveYN'] = df['offensiveYN'].fillna(-1)\n",
        "df['sexPhrase'] = df['sexPhrase'].fillna('')\n",
        "df['speakerMinorityYN'] = df['speakerMinorityYN'].fillna(-1)\n",
        "df['targetMinority'] = df['targetMinority'].fillna('')\n",
        "df['targetCategory'] = df['targetCategory'].fillna('')\n",
        "df['targetStereotype'] = df['targetStereotype'].fillna('')"
      ],
      "metadata": {
        "id": "HX-CLy1DiO7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "q4FlNyihiVxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_encode = ['post', 'sexReason',  'sexPhrase', 'targetMinority', 'targetStereotype']\n",
        "\n",
        "for column in to_encode:\n",
        "  print(f'Embedding {column}')\n",
        "  text = df[column]\n",
        "  embeddings = model.encode(text, show_progress_bar=True)\n",
        "  np.save(f'/content/embeddings_{column}_train.npy', embeddings)"
      ],
      "metadata": {
        "id": "8c4dQz4XiSpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['whoTarget', 'intentYN', 'sexYN', 'offensiveYN', 'speakerMinorityYN']]"
      ],
      "metadata": {
        "id": "Dgx1d74MibcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for embedding_column in to_encode:\n",
        "  print(f'Loading in embeddings for column {embedding_column}')\n",
        "  embeddings = np.load(f'/content/embeddings_{embedding_column}_train.npy')\n",
        "  X[embedding_column] = embeddings.tolist()"
      ],
      "metadata": {
        "id": "_yoCvhmcib2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = X.to_numpy()\n",
        "np.save('data.npy', array)"
      ],
      "metadata": {
        "id": "dt6sqguwis9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "ZHBeb_Hii6-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unpacked_columns = np.array([np.hstack(row[5:]) for row in X])  # Flatten columns 5 onwards\n",
        "result = np.hstack((X[:, :5], unpacked_columns))  # Combine the first 4 columns with the unpacked data"
      ],
      "metadata": {
        "id": "b1TQZroMi8Nz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clustering = AgglomerativeClustering(n_clusters=10, metric='cosine', linkage='average').fit(result) # change line for diff combos like euclidean and ward, or # of clusters"
      ],
      "metadata": {
        "id": "SfsNhA8gjcCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cluster_10.pkl', 'wb') as file: # again, example for a specific cluster count\n",
        "    pickle.dump(clustering, file)"
      ],
      "metadata": {
        "id": "0uhUzcJbjg7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = clustering.labels_"
      ],
      "metadata": {
        "id": "RDDHhctNte9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "categories = label_counts.index\n",
        "x = np.arange(len(categories))\n",
        "width = 0.1\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "bars = []\n",
        "for i in range(10):  # I adjusted this for each number of clusters\n",
        "    bars.append(ax.bar(x - (width * 3.5) + i * width, label_counts[i], width,\n",
        "                       label=f'{i}', color=plt.cm.get_cmap('tab10')(i), edgecolor='black'))\n",
        "\n",
        "\n",
        "ax.set_xlabel('Category', fontsize=18)\n",
        "ax.set_ylabel('Count', fontsize=18)\n",
        "ax.set_title('Ten Clusters -- Euclidean', fontsize=18)\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(categories)\n",
        "plt.xticks(fontsize=14)\n",
        "plt.yticks(fontsize=14)\n",
        "ax.legend(ncol=4, loc='upper center', bbox_to_anchor=(0.5, -0.3))\n",
        "fig.subplots_adjust(bottom=0.2)\n",
        "ax.set_xlabel('Category', labelpad=15)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('/content/ten_clusters_consistent.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S8tFaONBtj9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling"
      ],
      "metadata": {
        "id": "JDZtq_htt7hf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_all = np.load('/content/data.npy', allow_pickle=True)\n",
        "X_test = X_all[5000:8000]\n",
        "X = X_all[:5000]"
      ],
      "metadata": {
        "id": "v1E9r9Mdtx0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT = {\n",
        "    'post': X[:, 5],\n",
        "}\n",
        "TEST_INPUT = {\n",
        "    'post': X_test[:, 5],\n",
        "}"
      ],
      "metadata": {
        "id": "6Vbvh7Qkt6tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lbe = LabelEncoder()\n",
        "TEST_OUTPUT = X_test[:, 1].astype(np.float32)\n",
        "TEST_OUTPUT = lbe.fit_transform(TEST_OUTPUT)\n",
        "\n",
        "OUTPUT = X[:, 1].astype(np.float32)\n",
        "OUTPUT = lbe.fit_transform(OUTPUT)"
      ],
      "metadata": {
        "id": "7q2Y8Kn1uEqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in INPUT:\n",
        "  if isinstance(INPUT[key][0], list):\n",
        "    nested_arrays = [np.array(inner_list, dtype=np.float32) for inner_list in INPUT[key]]\n",
        "    INPUT[key] = np.array(nested_arrays, dtype=np.float32)"
      ],
      "metadata": {
        "id": "sjC2rXV3uJ_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in TEST_INPUT:\n",
        "  if isinstance(TEST_INPUT[key][0], list):\n",
        "    nested_arrays = [np.array(inner_list, dtype=np.float32) for inner_list in TEST_INPUT[key]]\n",
        "    TEST_INPUT[key] = np.array(nested_arrays, dtype=np.float32)"
      ],
      "metadata": {
        "id": "Qf184PZ3wERV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_gender = torch.from_numpy(INPUT['post'])\n",
        "y_train_gender = torch.from_numpy(np.expand_dims(OUTPUT, 1).astype(np.float32))\n",
        "\n",
        "train_dataset_gender = TensorDataset(X_train_gender, y_train_gender)\n",
        "train_loader_gender = DataLoader(train_dataset_gender, batch_size=32, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "wdMkcXZ9uPuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "class ClassifierNN(nn.Module):\n",
        "   def __init__(self, input_dim, num_classes, seq_length, hidden_dim=128, nhead=4, num_encoder_layers=2):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 128)\n",
        "        self.transformer_encoder_layer = nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=nhead)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(self.transformer_encoder_layer, num_layers=num_encoder_layers)\n",
        "        self.classify = nn.Linear(hidden_dim, num_classes)\n",
        "   def forward(self, x):\n",
        "        x = self.transformer_encoder(torch.relu(self.fc1(x)).unsqueeze(1))\n",
        "        x = x[:, -1, :]\n",
        "        x = self.classify(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "g2fhxLeWubdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train_gender.shape[1]\n",
        "num_classes = 5\n",
        "seq_length = 1\n",
        "model = ClassifierNN(input_dim, num_classes, seq_length)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "RUkdo09eu_aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  loss_total = 0\n",
        "  for inputs, labels in train_loader_gender:\n",
        "    outputs = model(inputs)\n",
        "    labels = labels.squeeze().long()\n",
        "    loss = crit(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss_total += loss.item()\n",
        "  print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader_gender)}\")"
      ],
      "metadata": {
        "id": "SvsJN5IOvOZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/SBIC.v2.trn.csv')\n",
        "df_test = df[5000:8000]"
      ],
      "metadata": {
        "id": "b8gGActQwJJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_indices_test = df_test[df_test['targetCategory'] == 'gender'].index - 5000\n",
        "X_test_gender = torch.from_numpy(TEST_INPUT['post'][gender_indices_test])\n",
        "y_test_gender = torch.from_numpy(TEST_OUTPUT[gender_indices_test]).squeeze()\n",
        "\n",
        "test_dataset = TensorDataset(X_test_gender, y_test_gender)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "sukAFniEwHOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, dataloader, criterion, device='cpu'):\n",
        "    model.eval()\n",
        "    loss_total = 0\n",
        "    correct_preds = 0\n",
        "    total_preds = 0\n",
        "    tp = 0\n",
        "    tn = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    with torch.no_grad():\n",
        "      for inputs, labels in dataloader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        labels = labels.squeeze().long()\n",
        "        loss = crit(outputs, labels)\n",
        "        loss_total += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_preds += (predicted == labels).sum().item()\n",
        "        total_preds += labels.size(0)\n",
        "\n",
        "        positive_pred = (predicted == 2) | (predicted == 3) # intent to offend is either probably or definitely\n",
        "        negative_pred = (predicted == 0) | (predicted == 1) # intent to offend is probably not or definitely not\n",
        "\n",
        "        positive_labels = (labels == 2) | (labels == 3)\n",
        "        negative_labels = (labels == 0) | (labels == 1)\n",
        "\n",
        "        fn += (positive_labels & negative_pred).sum().item()\n",
        "        tn += (negative_labels & negative_pred).sum().item()\n",
        "        tp += (positive_labels & positive_pred).sum().item()\n",
        "        fp += (negative_labels & positive_pred).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    accuracy = correct_preds / total_preds * 100\n",
        "    precision = tp / (tp + fp) * 100\n",
        "    recall = tp / (tp + fn) * 100\n",
        "    f1 = (2 * precision * recall) / (precision + recall)\n",
        "    return avg_loss, accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "APtenZbQwT9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_loss, accuracy, precision, recall, f1 = evaluate_model(model, test_loader, crit, device)\n",
        "\n",
        "print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%, Precision: {precision:.2f}%, , Recall: {recall:.2f}%, , F1: {f1:.2f}%\")"
      ],
      "metadata": {
        "id": "GpfUOzIlwzyD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}